{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df13fae",
   "metadata": {},
   "source": [
    "## Goals\n",
    "Write a program that I can modify any time that will modify the labels for the training and validation dataset\n",
    " - Remove Percentages (unless there is EPI in the rest of the sentence?)\n",
    " - Tag ones of the form '1:100,000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f196ff2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk import tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a725df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important sets of words\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import string\n",
    "PUNCTUATION = set(char for char in string.punctuation)\n",
    "INCLUSIVE_WORDS = {'between','around','approximately','about','<','>','roughly','relatively','over','under','than'}#less than, greater than\n",
    "EPI_MODIFIERS = {'annual','overall','estimated','weighted','nationwide','pooled','average','cumulative'}\n",
    "DATES = {'january','february','march','april','may','june','july','august','september','october','november','december'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86256ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4580 4580\n"
     ]
    }
   ],
   "source": [
    "epi_train_tokens, epi_train_labels= [],[]\n",
    "with open('epi_train_setV2.tsv','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentence_tokens,sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                if len(sentence_tokens) != len(sentences_tags):\n",
    "                    print('uh oh', sentence_tokens, sentences_tags, sep='\\n')\n",
    "                epi_train_tokens.append(sentence_tokens.copy())\n",
    "                epi_train_labels.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(epi_train_tokens),len(epi_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6746615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227 1227\n"
     ]
    }
   ],
   "source": [
    "epi_val_tokens, epi_val_labels= [],[]\n",
    "with open('epi_val_setV2.tsv','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentence_tokens,sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                epi_val_tokens.append(sentence_tokens.copy())\n",
    "                epi_val_labels.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(epi_val_tokens),len(epi_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6837ddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534 534\n"
     ]
    }
   ],
   "source": [
    "#Need to modify t to calculate\n",
    "epi_test_tokens, epi_test_labels= [],[]\n",
    "with open('epi_test_setV2.tsv','r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentence_tokens,sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                epi_test_tokens.append(sentence_tokens.copy())\n",
    "                epi_test_labels.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()\n",
    "print(len(epi_test_tokens),len(epi_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b882ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats(tokens,labels): #this is with lists of tokens, not lists of sentences which are lists of tokens\n",
    "    for i in range(1,len(labels)-1):\n",
    "        if 'STAT' in labels[i]:\n",
    "            #Includes <, > number in the statistic\n",
    "            if tokens[i-1]=='<' or tokens[i-1]=='>':\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "            #Includes greater than, less than, more than, etc. \n",
    "            if tokens[i-1]=='than':\n",
    "                labels[i-2]='B-STAT'\n",
    "                labels[i-1]='I-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                \n",
    "        #Combines \"This disease affects 1 in 7500 to 1 in 10,000 people\" into a single statistic phrase instead of 2\n",
    "        if 'STAT' in labels[i-1] and 'STAT' in labels[i+1] and 'STAT' not in labels[i]:\n",
    "            if tokens[i] =='to':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "            if tokens[i] =='-':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "        \n",
    "        #This gets of the type \"prevalence of 2 to 18 per 100,000\"\n",
    "        if labels[i+1]=='B-STAT':\n",
    "            if tokens[i]=='to' or tokens[i]=='-' or tokens[i-1].isdigit():\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "    return tokens,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35786153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def modify_labels(tokens,labels):\n",
    "    if len(tokens)!=len(labels):\n",
    "        raise IndexError(\"Num Sentences {} and Num Sentence Labels {} Mismatch\".format(len(tokens),len(labels)))\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i])!=len(labels[i]):\n",
    "            raise IndexError(\"Sentence Length {} and Label Length {} Mismatch\".format(len(tokens[i]),len(labels[i])))\n",
    "        '''\n",
    "        #Comparison loop\n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if labels[i][j]=='B-STAT':\n",
    "                print('BEFORE')\n",
    "                print(tokens[i][j-2:j+3])\n",
    "                print(labels[i][j-2:j+3])\n",
    "                print('')\n",
    "        '''\n",
    "        for j in range(len(tokens[i])):\n",
    "            if tokens[i][j]=='prevalent' or tokens[i][j]=='occurs':\n",
    "                labels[i][j] = 'B-EPI'\n",
    "        \n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if tokens[i][j].lower() in DATES:\n",
    "                labels[i][j]='O'\n",
    "                labels[i][j+1]='O'\n",
    "                labels[i][j+2]='O'\n",
    "                \n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if tokens[i][j-1].lower() in DATES:\n",
    "                labels[i][j-1]='O'\n",
    "                labels[i][j]='O'\n",
    "                labels[i][j+1]='O'\n",
    "                labels[i][j+2]='O'\n",
    "            \n",
    "            #Ensures that there is not already a label\n",
    "            if labels[i][j] in {'O','B-STAT','I-STAT'}:\n",
    "                #relabel all of the percentages\n",
    "                '''\n",
    "                if '%' in tokens[i][j]:\n",
    "                    print('BEFORE')\n",
    "                    print(tokens[i][j-2:j+3])\n",
    "                    print(labels[i][j-2:j+3])\n",
    "                    print('')\n",
    "                '''\n",
    "                #only include small percentages of the form '0.*'\n",
    "                if (('%' in tokens[i][j] or ('per' in tokens[i][j].lower() and 'cent' in tokens[i][j+1].lower()) or 'percent' in tokens[i][j].lower()\n",
    "                    ) and not (re.match(r\"^0\\.\", tokens[i][j]\n",
    "                    ) or re.match(r\"^0\\.\", tokens[i][j-1]\n",
    "                    ) or re.match(r\"^0\\.\", tokens[i][j-2]))\n",
    "                    ) and not ('B-EPI' in set(labels[i][j-2:j+3]) or 'I-EPI' in set(labels[i][j-2:j+3])):\n",
    "                    labels[i][j-2] = 'O'\n",
    "                    labels[i][j-1] = 'O'\n",
    "                    labels[i][j] = 'O'\n",
    "                    labels[i][j+1] = 'O'\n",
    "                    labels[i][j+2] = 'O'\n",
    "                '''\n",
    "                if '%' in tokens[i][j]:\n",
    "                    print('AFTER')\n",
    "                    print(tokens[i][j-2:j+3])\n",
    "                    print(labels[i][j-2:j+3])\n",
    "                    print('\\n')\n",
    "                '''\n",
    "                #gets of the form 1:100,000\n",
    "                #tag word before except if it is 'of' or label before is there\n",
    "                if tokens[i][j][0].isdigit() and ':' in tokens[i][j]:\n",
    "                    #print(tokens[i][j-2:j+3])\n",
    "                    #print(labels[i][j-2:j+3])\n",
    "                    #print(tokens[i][j].split(':'))\n",
    "                    #Exclude\n",
    "                    if ((len(tokens[i][j])==5 and not tokens[i][j+1][0].isdigit()) or len(tokens[i][j].split(':')[0])>3):\n",
    "                        pass\n",
    "                        #continue\n",
    "                    #Exclude\n",
    "                    elif 'ratio' in tokens[i][j-2:j-1]:\n",
    "                        pass\n",
    "                        #continue\n",
    "                    else:\n",
    "                        if tokens[i][j-1].lower() in INCLUSIVE_WORDS:\n",
    "                            labels[i][j-1]='B-STAT'\n",
    "                            labels[i][j]='I-STAT'\n",
    "                        elif tokens[i][j-2].lower() in INCLUSIVE_WORDS:\n",
    "                            labels[i][j-2]='B-STAT'\n",
    "                            labels[i][j-1]='I-STAT'\n",
    "                            labels[i][j]='I-STAT'\n",
    "                        else:\n",
    "                            labels[i][j]='B-STAT'\n",
    "\n",
    "                        if tokens[i][j+1][0].isdigit():\n",
    "                            labels[i][j+1]='I-STAT'\n",
    "                            if (tokens[i][j+2].lower() not in STOPWORDS and tokens[i][j+2] not in PUNCTUATION) and labels[i][j+2] in {'O','B-STAT','I-STAT'}:\n",
    "                                labels[i][j+2]='I-STAT'\n",
    "                                #Could potentially cause an indexing issue?\n",
    "                                labels[i][j+3]='I-STAT'\n",
    "                        if (tokens[i][j+1].lower() not in STOPWORDS and tokens[i][j+1] not in PUNCTUATION) and labels[i][j+1] in {'O','B-STAT','I-STAT'}:\n",
    "                            labels[i][j+1]='I-STAT'\n",
    "                            #Checks to make sure it is not already tagged\n",
    "                            if labels[i][j+2] in {'O','B-STAT'}:\n",
    "                                labels[i][j+2]='I-STAT'\n",
    "                                \n",
    "                            \n",
    "        for j in range(1,len(tokens[i])-1):\n",
    "            if tokens[i][j].lower() == 'unknown' and (labels[i][j+1]=='B-EPI' or labels[i][j+1]=='I-EPI'):\n",
    "                labels[i][j]='B-STAT'\n",
    "            if tokens[i][j].lower() == 'global' and (labels[i][j+1]=='B-EPI' or labels[i][j+1]=='I-EPI'):\n",
    "                labels[i][j]='B-LOC'\n",
    "            #Gets the ones who have cut off numbers\n",
    "            if labels[i][j]=='I-STAT' and labels[i][j+1]=='O':\n",
    "                if tokens[i][j+1][0].isdigit():\n",
    "                    labels[i][j+1]='I-STAT'\n",
    "            \n",
    "            if labels[i][j]=='B-STAT':\n",
    "                #This is supposed to match years, but not sure how well, did not test, copied from stackoverflow\n",
    "                if re.match(r\"^[12][0-9]{3}$\",tokens[i][j].split('/')[0]):\n",
    "                    labels[i][j]='O'\n",
    "                #gets rid of incessant 'was' being tagged\n",
    "                if tokens[i][j].lower() in STOPWORDS:\n",
    "                    labels[i][j]='O'\n",
    "                    labels[i][j+1]='B-STAT'\n",
    "            #Lengthens tags to include descriptors, there could bee more to include, but did not pop out during testing\n",
    "            if (labels[i][j-1] =='I-STAT' or labels[i][j-1] =='B-STAT') and labels[i][j] =='O':\n",
    "                if tokens[i][j+1] in {'births','LBs','LB','birth'}:\n",
    "                    labels[i][j]='I-STAT'\n",
    "                    labels[i][j+1]='I-STAT'\n",
    "                elif tokens[i][j] in {'births','LBs','LB','birth'}:\n",
    "                    labels[i][j]='I-STAT'\n",
    "            #This should also lengthen epi tags a little bit to include descriptors\n",
    "            if labels[i][j]=='B-EPI' and tokens[i][j-1].lower() in EPI_MODIFIERS:\n",
    "                labels[i][j-1]='B-EPI'\n",
    "                labels[i][j]='I-EPI'\n",
    "            \n",
    "            ## This was not in V3.1, this is the final change that created the V3.2 dataset. Everything else is the same\n",
    "            #This should remove isolated stats that do not have epi in the rest of the sentence\n",
    "            if labels[i][j-1]=='B-STAT' and labels[i][j]!='I-STAT' and 'B-EPI' not in labels[i]:\n",
    "                if '/' in tokens[i][j-1]:\n",
    "                    if len(tokens[i][j-1])<9 or '+' in tokens[i][j-1] or '-' in tokens[i][j-1] or 'Â±' in tokens[i][j-1]:\n",
    "                        labels[i][j-1]=='O'\n",
    "                    else:\n",
    "                        #leave out the ones like ['1.21/10,000', 'individuals', ')'] ['B-STAT', 'O', 'O']\n",
    "                        pass\n",
    "                else:\n",
    "                    labels[i][j-1]=='O'\n",
    "\n",
    "        tokens, labels = combine_stats(tokens,labels)\n",
    "        '''\n",
    "        #Comparison loop\n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "                \n",
    "            if labels[i][j]=='B-STAT':\n",
    "                print('AFTER')\n",
    "                print(tokens[i][j-2:j+3])\n",
    "                print(labels[i][j-2:j+3])\n",
    "                print('\\n')\n",
    "        '''\n",
    "        if i %250==0:\n",
    "            print(i)\n",
    "            \n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4b264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "mod_train_tokens, mod_train_labels = modify_labels(epi_train_tokens,epi_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0e0bef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "mod_val_tokens, mod_val_labels = modify_labels(epi_val_tokens,epi_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c61f7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "mod_test_tokens, mod_test_labels = modify_labels(epi_test_tokens,epi_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8cfc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('epi_train_setV3.tsv', \"w\") as f:\n",
    "    for i in range(len(mod_train_tokens)): #For sentence in list of sentences\n",
    "        for j in range(len(mod_train_tokens[i])): #for token in sentence\n",
    "            output = str(mod_train_tokens[i][j]) +'\\t' +str(mod_train_labels[i][j])+'\\n'\n",
    "            f.write(output)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f33eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('epi_val_setV3.tsv', \"w\") as f:\n",
    "    for i in range(len(mod_val_tokens)): #For sentence in list of sentences\n",
    "        for j in range(len(mod_val_tokens[i])): #for token in sentence\n",
    "            output = str(mod_val_tokens[i][j]) +'\\t' +str(mod_val_labels[i][j])+'\\n'\n",
    "            f.write(output)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d2ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('epi_test_setV3.tsv', \"w\") as f:\n",
    "    for i in range(len(mod_test_tokens)): #For sentence in list of sentences\n",
    "        for j in range(len(mod_test_tokens[i])): #for token in sentence\n",
    "            output = str(mod_test_tokens[i][j]) +'\\t' +str(mod_test_labels[i][j])+'\\n'\n",
    "            f.write(output)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
