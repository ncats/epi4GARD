{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe73f8d",
   "metadata": {},
   "source": [
    "This is going to be where the final training datasets are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ef6687",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conllpp (/work/wzkariampuzha/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "coNLL = load_dataset(\"conllpp\")\n",
    "coNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e183fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER_tag '5' is B-LOC, '6' is I-LOC\n",
    "def read_dataset(dataset):\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for sentence in dataset:\n",
    "        #Only add sentences that actually have location tags (i.e. meaningfully annotated sentences)\n",
    "        if (5 in sentence['ner_tags'] or 6 in sentence['ner_tags']):\n",
    "            i=0\n",
    "            tokens = []\n",
    "            tags = []\n",
    "            for tag in sentence['ner_tags']:\n",
    "                label = 'O'\n",
    "                if tag ==5:\n",
    "                    label = 'B-LOC'\n",
    "                if tag == 6:\n",
    "                    label = 'I-LOC'\n",
    "                #print(sentence['tokens'][i], label)\n",
    "                tokens.append(sentence['tokens'][i])\n",
    "                tags.append(label)\n",
    "                i+=1\n",
    "            token_docs.append(tokens)\n",
    "            tag_docs.append(tags)\n",
    "    return token_docs, tag_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd753c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_tags = read_dataset(coNLL[\"train\"])\n",
    "validation_texts, validation_tags = read_dataset(coNLL[\"validation\"])\n",
    "test_texts, train_tags = read_dataset(coNLL[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc40113b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN']\n",
      "['O', 'O', 'B-LOC', 'O', 'O', 'O']\n",
      "['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
      "['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(test_texts[i][:6], train_tags[i][:6],sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7b5a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O', 'I-LOC', 'B-LOC'}\n",
      "{'O': 0, 'I-LOC': 1, 'B-LOC': 2}\n",
      "{0: 'O', 1: 'I-LOC', 2: 'B-LOC'}\n"
     ]
    }
   ],
   "source": [
    "unique_tags = set(tag for doc in train_tags for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "print(unique_tags)\n",
    "print(tag2id)\n",
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c09a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "#Figure out if need pretrained tokenizer fast, bc using it for return_offsets_mapping, but if dont need it, then use regular bert tokenizer\n",
    "#from transformers import BertTokenizer\n",
    "#tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
    "\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('bert-base-cased')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True, max_length=192)\n",
    "val_encodings = tokenizer(validation_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True, max_length=192)\n",
    "test_encodings = tokenizer(test_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True, max_length=192) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9e6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_tags(tags, encodings):\n",
    "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65de9cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NumPy boolean array indexing assignment cannot assign 12 input values to the 2 output values where the mask is true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37472/1778167475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37472/3521536413.py\u001b[0m in \u001b[0;36mencode_tags\u001b[0;34m(tags, encodings)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# set labels whose first offset position is 0 and the second is not 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_offset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mencoded_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_enc_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NumPy boolean array indexing assignment cannot assign 12 input values to the 2 output values where the mask is true"
     ]
    }
   ],
   "source": [
    "train_labels = encode_tags(train_tags, train_encodings)\n",
    "val_labels = encode_tags(validation_tags, val_encodings)\n",
    "test_labels = encode_tags(train_tags, test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce9023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CoNLLDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
    "val_encodings.pop(\"offset_mapping\")\n",
    "test_encodings.pop(\"offset_mapping\")\n",
    "train_dataset = CoNLLDataset(train_encodings, train_labels)\n",
    "val_dataset = CoNLLDataset(val_encodings, val_labels)\n",
    "test_dataset = CoNLLDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57651319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "model = BertForTokenClassification.from_pretrained('dmis-lab/biobert-large-cased-v1.1', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de8a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    seed = 1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    test_dataset=\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab55818",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "#Seed is a helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb060c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "# For convenience, we also re-save the tokenizer to the same directory,\n",
    "# so that you can share your model easily on huggingface.co/models =)\n",
    "if trainer.is_world_process_zero():\n",
    "    tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48aeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "def align_predictions(predictions: np.ndarray, label_ids: np.ndarray): # -> Tuple[List[int], List[int]]\n",
    "        preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "        batch_size, seq_len = preds.shape\n",
    "\n",
    "        out_label_list = [[] for _ in range(batch_size)]\n",
    "        preds_list = [[] for _ in range(batch_size)]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                if label_ids[i, j] != nn.CrossEntropyLoss().ignore_index:\n",
    "                    out_label_list[i].append(label_map[label_ids[i][j]])\n",
    "                    preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "        return preds_list, out_label_list\n",
    "\n",
    "def compute_metrics(p: EvalPrediction): #-> Dict\n",
    "    preds_list, out_label_list = align_predictions(p.predictions, p.label_ids)\n",
    "    return {\n",
    "        \"precision\": precision_score(out_label_list, preds_list),\n",
    "        \"recall\": recall_score(out_label_list, preds_list),\n",
    "        \"f1\": f1_score(out_label_list, preds_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "results = {}\n",
    "result = trainer.evaluate()\n",
    "output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        for key, value in result.items():\n",
    "            writer.write(\"%s = %s\\n\" % (key, value))\n",
    "            results.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be406f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predictions\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset)\n",
    "preds_list, _ = align_predictions(predictions, label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e85b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "output_test_results_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_test_results_file, \"w\") as writer:\n",
    "        for key, value in metrics.items():\n",
    "            writer.write(\"%s = %s\\n\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_predictions_file = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_test_predictions_file, \"w\") as writer:\n",
    "        with open(os.path.join(data_args.data_dir, \"test.txt\"), \"r\") as f:\n",
    "            example_id = 0\n",
    "                for line in f:\n",
    "                    if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
    "                        writer.write(line)\n",
    "                        if not preds_list[example_id]:\n",
    "                            example_id += 1\n",
    "                    elif preds_list[example_id]:\n",
    "                        entity_label = preds_list[example_id].pop(0)\n",
    "                        if entity_label == 'O':\n",
    "                            output_line = line.split()[0] + \" \" + entity_label + \"\\n\"\n",
    "                        else:\n",
    "                            output_line = line.split()[0] + \" \" + entity_label[0] + \"\\n\"\n",
    "                            # output_line = line.split()[0] + \" \" + preds_list[example_id].pop(0) + \"\\n\"\n",
    "                            writer.write(output_line)\n",
    "                    else:\n",
    "                        print(\"Maximum sequence length exceeded: No prediction for '%s'.\", line.split()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
