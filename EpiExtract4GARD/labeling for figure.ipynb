{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import string\n",
    "PUNCTUATION = set(char for char in string.punctuation)\n",
    "import csv\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from classify_abs import get_abstract\n",
    "import string\n",
    "PUNCTUATION = set(char for char in string.punctuation)\n",
    "INCLUSIVE_WORDS = {'between','around','approximately','about','<','>','roughly','relatively','over','under','than'}#less than, greater than\n",
    "EPI_MODIFIERS = {'annual','overall','estimated','weighted','nationwide','pooled','average','cumulative'}\n",
    "DATES = {'january','february','march','april','may','june','july','august','september','october','november','december'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The aim of this retrospective study was to determine the prevalence of lysosomal storage disorders (LSDs) in the Czech Republic. The data on cases diagnosed between 1975 and 2008 were collected and analyzed. The overall prevalence of LSDs in the Czech population (12.25 per 100,000) is comparable to that reported for the countries with well-established and advanced diagnostics of LSDs such as the Netherlands (14 per 100,000), Australia (12.9 per 100,000) and Italy (12.1 per 100,000). Relatively higher prevalence of LSDs was reported in the north of Portugal (25 per 100,000). Thirty-four different LSDs were diagnosed in a total of 478 individuals. Gaucher disease was the most frequent LSD with a birth prevalence of 1.13 per 100,000 births. The most frequent LSD groups were lipidoses, mucopolysaccharidoses, and neuronal ceroid lipofuscinoses, with combined prevalences of 5.0, 3.72, and 2.29 per 100,000 live births, respectively. Glycoproteinoses (0.57 per 100,000 live births), glycogenosis type II (0.37), and mucolipidoses (0.31) rarely occur in the Czech population, and a range of other LSDs have not been detected at all over the past three decades. Knowledge of the birth prevalence and carrier frequency of particular disorders is important in genetic counselling for calculation of the risk for the disorder in the other members of affected families. Earlier diagnosis of these disorders will permit timely intervention and may also result in lowering of the number of newborns with LSDs.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = get_abstract(20490927)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(string):\n",
    "    string = re.sub('<.{1,4}>', ' ', string)\n",
    "    string = re.sub(\"  *\", \" \" , string)\n",
    "    string = re.sub(\"^ \", \"\" , string)\n",
    "    string = re.sub(\" $\", \"\" , string)\n",
    "    string = re.sub(\"  \", \" \" , string)\n",
    "    string=string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Map label onto each word (done rule-based at the sentence level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy named entities are here: https://spacy.io/models/en \n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats1(tokens,labels):\n",
    "    i=1\n",
    "    while i<len(labels)-1:\n",
    "        if 'STAT' in labels[i]:\n",
    "            #Includes <, > number in the statistic\n",
    "            if tokens[i-1]=='<' or tokens[i-1]=='>':\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "            #Includes greater than, less than, more than, etc. \n",
    "            if tokens[i-1]=='than':\n",
    "                labels[i-2]='B-STAT'\n",
    "                labels[i-1]='I-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                \n",
    "        #Combines \"This disease affects 1 in 7500 to 1 in 10,000 people\" into a single statistic phrase instead of 2\n",
    "        if 'STAT' in labels[i-1] and 'STAT' in labels[i+1] and 'STAT' not in labels[i]:\n",
    "            if tokens[i] =='to':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "            if tokens[i] =='-':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "        \n",
    "        #This gets of the type \"prevalence of 2 to 18 per 100,000\"\n",
    "        if labels[i+1]=='B-STAT':\n",
    "            if tokens[i]=='to' or tokens[i]=='-' or tokens[i-1].isdigit():\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "        i+=1\n",
    "    return tokens,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stats2(tokens,labels): #this is with lists of tokens, not lists of sentences which are lists of tokens\n",
    "    for i in range(1,len(labels)-1):\n",
    "        if 'STAT' in labels[i]:\n",
    "            #Includes <, > number in the statistic\n",
    "            if tokens[i-1]=='<' or tokens[i-1]=='>':\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "            #Includes greater than, less than, more than, etc. \n",
    "            if tokens[i-1]=='than':\n",
    "                labels[i-2]='B-STAT'\n",
    "                labels[i-1]='I-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                \n",
    "        #Combines \"This disease affects 1 in 7500 to 1 in 10,000 people\" into a single statistic phrase instead of 2\n",
    "        if 'STAT' in labels[i-1] and 'STAT' in labels[i+1] and 'STAT' not in labels[i]:\n",
    "            if tokens[i] =='to':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "            if tokens[i] =='-':\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "        \n",
    "        #This gets of the type \"prevalence of 2 to 18 per 100,000\"\n",
    "        if labels[i+1]=='B-STAT':\n",
    "            if tokens[i]=='to' or tokens[i]=='-' or tokens[i-1].isdigit():\n",
    "                labels[i-1]='B-STAT'\n",
    "                labels[i]='I-STAT'\n",
    "                labels[i+1]='I-STAT'\n",
    "    \n",
    "    return tokens,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_labels(tokens,labels):\n",
    "    if len(tokens)!=len(labels):\n",
    "        raise IndexError(\"Num Sentences {} and Num Sentence Labels {} Mismatch\".format(len(tokens),len(labels)))\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i])!=len(labels[i]):\n",
    "            raise IndexError(\"Sentence Length {} and Label Length {} Mismatch\".format(len(tokens[i]),len(labels[i])))\n",
    "        '''\n",
    "        #Comparison loop\n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if labels[i][j]=='B-STAT':\n",
    "                print('BEFORE')\n",
    "                print(tokens[i][j-2:j+3])\n",
    "                print(labels[i][j-2:j+3])\n",
    "                print('')\n",
    "        '''\n",
    "        for j in range(len(tokens[i])):\n",
    "            if tokens[i][j]=='prevalent' or tokens[i][j]=='occurs':\n",
    "                labels[i][j] = 'B-EPI'\n",
    "        \n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if tokens[i][j].lower() in DATES:\n",
    "                labels[i][j]='O'\n",
    "                labels[i][j+1]='O'\n",
    "                labels[i][j+2]='O'\n",
    "                \n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "            if tokens[i][j-1].lower() in DATES:\n",
    "                labels[i][j-1]='O'\n",
    "                labels[i][j]='O'\n",
    "                labels[i][j+1]='O'\n",
    "                labels[i][j+2]='O'\n",
    "            \n",
    "            #Ensures that there is not already a label\n",
    "            if labels[i][j] in {'O','B-STAT','I-STAT'}:\n",
    "                #relabel all of the percentages\n",
    "                '''\n",
    "                if '%' in tokens[i][j]:\n",
    "                    print('BEFORE')\n",
    "                    print(tokens[i][j-2:j+3])\n",
    "                    print(labels[i][j-2:j+3])\n",
    "                    print('')\n",
    "                '''\n",
    "                #only include small percentages of the form '0.*'\n",
    "                if (('%' in tokens[i][j] or ('per' in tokens[i][j].lower() and 'cent' in tokens[i][j+1].lower()) or 'percent' in tokens[i][j].lower()\n",
    "                    ) and not (re.match(r\"^0\\.\", tokens[i][j]\n",
    "                    ) or re.match(r\"^0\\.\", tokens[i][j-1]\n",
    "                    ) or re.match(r\"^0\\.\", tokens[i][j-2]))\n",
    "                    ) and not ('B-EPI' in set(labels[i][j-2:j+3]) or 'I-EPI' in set(labels[i][j-2:j+3])):\n",
    "                    labels[i][j-2] = 'O'\n",
    "                    labels[i][j-1] = 'O'\n",
    "                    labels[i][j] = 'O'\n",
    "                    labels[i][j+1] = 'O'\n",
    "                    labels[i][j+2] = 'O'\n",
    "                '''\n",
    "                if '%' in tokens[i][j]:\n",
    "                    print('AFTER')\n",
    "                    print(tokens[i][j-2:j+3])\n",
    "                    print(labels[i][j-2:j+3])\n",
    "                    print('\\n')\n",
    "                '''\n",
    "                #gets of the form 1:100,000\n",
    "                #tag word before except if it is 'of' or label before is there\n",
    "                if tokens[i][j][0].isdigit() and ':' in tokens[i][j]:\n",
    "                    #print(tokens[i][j-2:j+3])\n",
    "                    #print(labels[i][j-2:j+3])\n",
    "                    #print(tokens[i][j].split(':'))\n",
    "                    #Exclude\n",
    "                    if ((len(tokens[i][j])==5 and not tokens[i][j+1][0].isdigit()) or len(tokens[i][j].split(':')[0])>3):\n",
    "                        pass\n",
    "                        #continue\n",
    "                    #Exclude\n",
    "                    elif 'ratio' in tokens[i][j-2:j-1]:\n",
    "                        pass\n",
    "                        #continue\n",
    "                    else:\n",
    "                        if tokens[i][j-1].lower() in INCLUSIVE_WORDS:\n",
    "                            labels[i][j-1]='B-STAT'\n",
    "                            labels[i][j]='I-STAT'\n",
    "                        elif tokens[i][j-2].lower() in INCLUSIVE_WORDS:\n",
    "                            labels[i][j-2]='B-STAT'\n",
    "                            labels[i][j-1]='I-STAT'\n",
    "                            labels[i][j]='I-STAT'\n",
    "                        else:\n",
    "                            labels[i][j]='B-STAT'\n",
    "\n",
    "                        if tokens[i][j+1][0].isdigit():\n",
    "                            labels[i][j+1]='I-STAT'\n",
    "                            if (tokens[i][j+2].lower() not in STOPWORDS and tokens[i][j+2] not in PUNCTUATION) and labels[i][j+2] in {'O','B-STAT','I-STAT'}:\n",
    "                                labels[i][j+2]='I-STAT'\n",
    "                                #Could potentially cause an indexing issue?\n",
    "                                labels[i][j+3]='I-STAT'\n",
    "                        if (tokens[i][j+1].lower() not in STOPWORDS and tokens[i][j+1] not in PUNCTUATION) and labels[i][j+1] in {'O','B-STAT','I-STAT'}:\n",
    "                            labels[i][j+1]='I-STAT'\n",
    "                            #Checks to make sure it is not already tagged\n",
    "                            if labels[i][j+2] in {'O','B-STAT'}:\n",
    "                                labels[i][j+2]='I-STAT'\n",
    "                                \n",
    "                            \n",
    "        for j in range(1,len(tokens[i])-1):\n",
    "            if tokens[i][j].lower() == 'unknown' and (labels[i][j+1]=='B-EPI' or labels[i][j+1]=='I-EPI'):\n",
    "                labels[i][j]='B-STAT'\n",
    "            if tokens[i][j].lower() == 'global' and (labels[i][j+1]=='B-EPI' or labels[i][j+1]=='I-EPI'):\n",
    "                labels[i][j]='B-LOC'\n",
    "            #Gets the ones who have cut off numbers\n",
    "            if labels[i][j]=='I-STAT' and labels[i][j+1]=='O':\n",
    "                if tokens[i][j+1][0].isdigit():\n",
    "                    labels[i][j+1]='I-STAT'\n",
    "            \n",
    "            if labels[i][j]=='B-STAT':\n",
    "                #This is supposed to match years, but not sure how well, did not test, copied from stackoverflow\n",
    "                if re.match(r\"^[12][0-9]{3}$\",tokens[i][j].split('/')[0]):\n",
    "                    labels[i][j]='O'\n",
    "                #gets rid of incessant 'was' being tagged\n",
    "                if tokens[i][j].lower() in STOPWORDS:\n",
    "                    labels[i][j]='O'\n",
    "                    labels[i][j+1]='B-STAT'\n",
    "            #Lengthens tags to include descriptors, there could bee more to include, but did not pop out during testing\n",
    "            if (labels[i][j-1] =='I-STAT' or labels[i][j-1] =='B-STAT') and labels[i][j] =='O':\n",
    "                if tokens[i][j+1] in {'births','LBs','LB','birth'}:\n",
    "                    labels[i][j]='I-STAT'\n",
    "                    labels[i][j+1]='I-STAT'\n",
    "                elif tokens[i][j] in {'births','LBs','LB','birth'}:\n",
    "                    labels[i][j]='I-STAT'\n",
    "            #This should also lengthen epi tags a little bit to include descriptors\n",
    "            if labels[i][j]=='B-EPI' and tokens[i][j-1].lower() in EPI_MODIFIERS:\n",
    "                labels[i][j-1]='B-EPI'\n",
    "                labels[i][j]='I-EPI'\n",
    "            \n",
    "            ## This was not in V3.1, this is the final change that created the V3.2 dataset. Everything else is the same\n",
    "            #This should remove isolated stats that do not have epi in the rest of the sentence\n",
    "            if labels[i][j-1]=='B-STAT' and labels[i][j]!='I-STAT' and 'B-EPI' not in labels[i]:\n",
    "                if '/' in tokens[i][j-1]:\n",
    "                    if len(tokens[i][j-1])<9 or '+' in tokens[i][j-1] or '-' in tokens[i][j-1] or 'Â±' in tokens[i][j-1]:\n",
    "                        labels[i][j-1]=='O'\n",
    "                    else:\n",
    "                        #leave out the ones like ['1.21/10,000', 'individuals', ')'] ['B-STAT', 'O', 'O']\n",
    "                        pass\n",
    "                else:\n",
    "                    labels[i][j-1]=='O'\n",
    "\n",
    "        tokens, labels = combine_stats2(tokens,labels)\n",
    "        '''\n",
    "        #Comparison loop\n",
    "        for j in range(2,len(tokens[i])-2):\n",
    "                \n",
    "            if labels[i][j]=='B-STAT':\n",
    "                print('AFTER')\n",
    "                print(tokens[i][j-2:j+3])\n",
    "                print(labels[i][j-2:j+3])\n",
    "                print('\\n')\n",
    "        '''\n",
    "        if i %250==0:\n",
    "            print(i)\n",
    "            \n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should take in a sentence and output each word in it with a tentative label\n",
    "def tag_NERs(sentence):\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.text for token in doc]\n",
    "    labels = ['O' for token in doc]\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if len(str(token.text).strip())==0:\n",
    "            tokens.pop(i)\n",
    "            labels.pop(i)\n",
    "            \n",
    "        else:\n",
    "            ## Epidemiologic identifier\n",
    "            if token.text.lower() in {'incidence','prevalence','prevalences','prevalence ','incidences','occurrence','occurrences'}:\n",
    "                labels[i] = 'B-EPI'\n",
    "        \n",
    "            ## Location\n",
    "            if token.ent_type_ in {'GPE','LOC'}:\n",
    "                labels[i] = str(token.ent_iob_+'-LOC')\n",
    "            if token.text in {\"worldwide\"}:\n",
    "                labels[i] = 'B-LOC'\n",
    "        \n",
    "            ## Epidemiologic Rates\n",
    "            #This gets stuff of the form 3.5/100\n",
    "            if token.text[0].isdigit() and '/' in token.text:\n",
    "                labels[i] = 'B-STAT'\n",
    "        \n",
    "            #label all percents except those preceding \"confidence interval (CI)\"\n",
    "            if token.ent_type_ in {'PERCENT'}:# and token.text not in {'95', 'CI'}:\n",
    "                if i<len(doc)-2:\n",
    "                    if doc[i+2].text in {'CI','confidence','interval','confidence interval','(CI)','(CI','CI)'}:\n",
    "                        labels[i] = 'O'\n",
    "                        labels[i+1] = 'O'\n",
    "                        labels[i+2] = 'O'\n",
    "                    elif doc[i+1].text in {'CI','confidence','interval','confidence interval','(CI)','(CI','CI)'}:\n",
    "                        labels[i] = 'O'\n",
    "                        labels[i+1] = 'O'\n",
    "                    else:\n",
    "                        labels[i] = str(token.ent_iob_+'-STAT')\n",
    "                elif i<len(doc)-1:\n",
    "                    if doc[i+1].text in {'CI','confidence','interval','confidence interval','(CI)','(CI','CI)'}:\n",
    "                        labels[i] = 'O'\n",
    "                        labels[i+1] = 'O'\n",
    "                    else:\n",
    "                        labels[i] = str(token.ent_iob_+'-STAT')        \n",
    "                else:\n",
    "                    labels[i] = str(token.ent_iob_+'-STAT')\n",
    "        \n",
    "            #These 3 get stuff of the form \"one in 35000\" or \"one in every 23043\"\n",
    "            if (token.text.lower() in {'one','1'} and i<(len(doc)-3)): \n",
    "                if doc[i+3].is_digit:\n",
    "                    labels[i] = 'B-STAT'\n",
    "                    for j in range(i+1,i+4):\n",
    "                        labels[j] = 'I-STAT'\n",
    "            if (token.text.lower() in {'one','1'} and i<(len(doc)-2)): \n",
    "                if doc[i+2].is_digit:\n",
    "                    labels[i] = 'B-STAT'\n",
    "                    labels[i+1] = 'I-STAT'\n",
    "                    labels[i+2] = 'I-STAT'\n",
    "            if (token.text.lower() in {'one','1'} and i<(len(doc)-1)):\n",
    "                if doc[i+1].is_digit:\n",
    "                    labels[i] = 'B-STAT'\n",
    "                    labels[i+1] = 'I-STAT'\n",
    "        \n",
    "            #These should get the ones of the form: 14.1 deaths per 1,000 LBs\n",
    "            #This is a big decision tree, not sure how to write it in fewer lines of code\n",
    "            #Need to get all permutations of \"a b per c d e\" where (a or b) and (c or d) is number and e is anything, but if e does not exist still need to tag a-d as STAT\n",
    "            if token.text.lower() =='per':\n",
    "                #print(i,len(doc))\n",
    "                if i>1:\n",
    "                    if i<len(doc)-3:\n",
    "                        #Resulted in better testing when not validating that words after 'per' are numbers\n",
    "                        if (doc[i-2].is_digit or doc[i-2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+2].is_digit or doc[i+2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                            if tokens[i-2] not in STOPWORDS and tokens[i-2] not in PUNCTUATION:\n",
    "                                labels[i-2] = 'B-STAT'\n",
    "                                #labeling also the token after the number\n",
    "                                for j in range(i-1,i+3):\n",
    "                                    labels[j]='I-STAT'\n",
    "                            else:\n",
    "                                labels[i-1] = 'B-STAT'\n",
    "                                #labeling also the token after the number\n",
    "                                for j in range(i,i+3):\n",
    "                                    labels[j]='I-STAT'\n",
    "                            \n",
    "                    if i<len(doc)-2:\n",
    "                        if (doc[i-2].is_digit or doc[i-2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+2].is_digit or doc[i+2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                            if tokens[i-2] not in STOPWORDS and tokens[i-2] not in PUNCTUATION:\n",
    "                                labels[i-2] = 'B-STAT'\n",
    "                                #labeling also the token after the number\n",
    "                                for j in range(i-1,i+2):\n",
    "                                    labels[j]='I-STAT'\n",
    "                            else: \n",
    "                                labels[i-1] = 'B-STAT'\n",
    "                                #labeling also the token after the number\n",
    "                                for j in range(i,i+2):\n",
    "                                    labels[j]='I-STAT'\n",
    "                    #The difference between the above and below is in labeling the token immediately after the number\n",
    "                    if i<len(doc)-1:\n",
    "                        if (doc[i-2].is_digit or doc[i-2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+2].is_digit or doc[i+2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                            if tokens[i-2] not in STOPWORDS and tokens[i-2] not in PUNCTUATION:\n",
    "                                labels[i-2] = 'B-STAT'\n",
    "                                #labeling also the token after if it is number\n",
    "                                for j in range(i-1,i+1):\n",
    "                                    labels[j]='I-STAT'\n",
    "                            else: \n",
    "                                labels[i-1] = 'B-STAT'\n",
    "                                #labeling also the token after the number\n",
    "                                for j in range(i,i+1):\n",
    "                                    labels[j]='I-STAT'\n",
    "                elif i>0:\n",
    "                    if i<len(doc)-3:\n",
    "                        if (doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+2].is_digit or doc[i+2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                \n",
    "                            labels[i-1] = 'B-STAT'\n",
    "                            #labeling also the token after the number\n",
    "                            for j in range(i,i+3):\n",
    "                                labels[j]='I-STAT'\n",
    "                            \n",
    "                    if i<len(doc)-2:\n",
    "                        if (doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+2].is_digit or doc[i+2].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                        \n",
    "                            labels[i-1] = 'B-STAT'\n",
    "                            #labeling also the token after the number\n",
    "                            for j in range(i,i+2):\n",
    "                                labels[j]='I-STAT'\n",
    "                            \n",
    "                    if i<len(doc)-1:\n",
    "                        if (doc[i-1].is_digit or doc[i-1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}) or (\n",
    "                            doc[i+1].is_digit or doc[i+1].ent_type_ in {'CARDINAL','ORDINAL','QUANTITY','MONEY'}):\n",
    "                    \n",
    "                            labels[i-1] = 'B-STAT'\n",
    "                            #labeling just the number if there is nothing after. \n",
    "                            for j in range(i,i+1):\n",
    "                                labels[j]='I-STAT'\n",
    "            i+=1\n",
    "\n",
    "    if len(tokens) != len(labels):\n",
    "        raise ValueError('Token/Label Length Mismatch')\n",
    "        \n",
    "    if len(tokens)>2 and len(labels)>2:\n",
    "        tokens, labels = combine_stats1(tokens,labels)\n",
    "        tokens = [str(token) for token in tokens]\n",
    "        labels = [str(label) for label in labels]\n",
    "        tokens, labels = modify_labels([tokens],[labels])\n",
    "        \n",
    "    return tokens, labels #This returns as type Spacy.tokens, need to convert to strings at writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tag_NERs Function Testing Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The O\n",
      "aim O\n",
      "of O\n",
      "this O\n",
      "retrospective O\n",
      "study O\n",
      "was O\n",
      "to O\n",
      "determine O\n",
      "the O\n",
      "prevalence B-EPI\n",
      "of O\n",
      "lysosomal O\n",
      "storage O\n",
      "disorders O\n",
      "( O\n",
      "LSDs O\n",
      ") O\n",
      "in O\n",
      "the B-LOC\n",
      "Czech I-LOC\n",
      "Republic I-LOC\n",
      ". O\n",
      "\n",
      "0\n",
      "The O\n",
      "data O\n",
      "on O\n",
      "cases O\n",
      "diagnosed O\n",
      "between O\n",
      "1975 O\n",
      "and O\n",
      "2008 O\n",
      "were O\n",
      "collected O\n",
      "and O\n",
      "analyzed O\n",
      ". O\n",
      "\n",
      "0\n",
      "The O\n",
      "overall B-EPI\n",
      "prevalence I-EPI\n",
      "of O\n",
      "LSDs O\n",
      "in O\n",
      "the O\n",
      "Czech O\n",
      "population O\n",
      "( O\n",
      "12.25 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      ") I-STAT\n",
      "is O\n",
      "comparable O\n",
      "to O\n",
      "that O\n",
      "reported O\n",
      "for O\n",
      "the O\n",
      "countries O\n",
      "with O\n",
      "well O\n",
      "- O\n",
      "established O\n",
      "and O\n",
      "advanced O\n",
      "diagnostics O\n",
      "of O\n",
      "LSDs O\n",
      "such O\n",
      "as O\n",
      "the O\n",
      "Netherlands B-LOC\n",
      "( O\n",
      "14 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      ") I-STAT\n",
      ", O\n",
      "Australia B-LOC\n",
      "( O\n",
      "12.9 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      ") I-STAT\n",
      "and O\n",
      "Italy B-LOC\n",
      "( O\n",
      "12.1 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      ") I-STAT\n",
      ". O\n",
      "\n",
      "0\n",
      "Relatively O\n",
      "higher O\n",
      "prevalence B-EPI\n",
      "of O\n",
      "LSDs O\n",
      "was O\n",
      "reported O\n",
      "in O\n",
      "the O\n",
      "north O\n",
      "of O\n",
      "Portugal B-LOC\n",
      "( O\n",
      "25 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      ") I-STAT\n",
      ". O\n",
      "\n",
      "0\n",
      "Thirty O\n",
      "- O\n",
      "four O\n",
      "different O\n",
      "LSDs O\n",
      "were O\n",
      "diagnosed O\n",
      "in O\n",
      "a O\n",
      "total O\n",
      "of O\n",
      "478 O\n",
      "individuals O\n",
      ". O\n",
      "\n",
      "0\n",
      "Gaucher O\n",
      "disease O\n",
      "was O\n",
      "the O\n",
      "most O\n",
      "frequent O\n",
      "LSD O\n",
      "with O\n",
      "a O\n",
      "birth O\n",
      "prevalence B-EPI\n",
      "of O\n",
      "1.13 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      "births I-STAT\n",
      ". O\n",
      "\n",
      "0\n",
      "The O\n",
      "most O\n",
      "frequent O\n",
      "LSD O\n",
      "groups O\n",
      "were O\n",
      "lipidoses O\n",
      ", O\n",
      "mucopolysaccharidoses O\n",
      ", O\n",
      "and O\n",
      "neuronal O\n",
      "ceroid O\n",
      "lipofuscinoses O\n",
      ", O\n",
      "with O\n",
      "combined O\n",
      "prevalences B-EPI\n",
      "of O\n",
      "5.0 O\n",
      ", O\n",
      "3.72 O\n",
      ", O\n",
      "and O\n",
      "2.29 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      "live I-STAT\n",
      "births I-STAT\n",
      ", O\n",
      "respectively O\n",
      ". O\n",
      "\n",
      "0\n",
      "Glycoproteinoses O\n",
      "( O\n",
      "0.57 B-STAT\n",
      "per I-STAT\n",
      "100,000 I-STAT\n",
      "live I-STAT\n",
      "births I-STAT\n",
      ") O\n",
      ", O\n",
      "glycogenosis O\n",
      "type O\n",
      "II O\n",
      "( O\n",
      "0.37 O\n",
      ") O\n",
      ", O\n",
      "and O\n",
      "mucolipidoses O\n",
      "( O\n",
      "0.31 O\n",
      ") O\n",
      "rarely O\n",
      "occur O\n",
      "in O\n",
      "the O\n",
      "Czech O\n",
      "population O\n",
      ", O\n",
      "and O\n",
      "a O\n",
      "range O\n",
      "of O\n",
      "other O\n",
      "LSDs O\n",
      "have O\n",
      "not O\n",
      "been O\n",
      "detected O\n",
      "at O\n",
      "all O\n",
      "over O\n",
      "the O\n",
      "past O\n",
      "three O\n",
      "decades O\n",
      ". O\n",
      "\n",
      "0\n",
      "Knowledge O\n",
      "of O\n",
      "the O\n",
      "birth O\n",
      "prevalence B-EPI\n",
      "and O\n",
      "carrier O\n",
      "frequency O\n",
      "of O\n",
      "particular O\n",
      "disorders O\n",
      "is O\n",
      "important O\n",
      "in O\n",
      "genetic O\n",
      "counselling O\n",
      "for O\n",
      "calculation O\n",
      "of O\n",
      "the O\n",
      "risk O\n",
      "for O\n",
      "the O\n",
      "disorder O\n",
      "in O\n",
      "the O\n",
      "other O\n",
      "members O\n",
      "of O\n",
      "affected O\n",
      "families O\n",
      ". O\n",
      "\n",
      "0\n",
      "Earlier O\n",
      "diagnosis O\n",
      "of O\n",
      "these O\n",
      "disorders O\n",
      "will O\n",
      "permit O\n",
      "timely O\n",
      "intervention O\n",
      "and O\n",
      "may O\n",
      "also O\n",
      "result O\n",
      "in O\n",
      "lowering O\n",
      "of O\n",
      "the O\n",
      "number O\n",
      "of O\n",
      "newborns O\n",
      "with O\n",
      "LSDs O\n",
      ". O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize.sent_tokenize(remove_html(abstract))\n",
    "\n",
    "for sentence in sentences:\n",
    "    t,l = tag_NERs(sentence)\n",
    "    for i in range(len(t)):\n",
    "        for j in range(len(t[i])):\n",
    "            print(t[i][j], l[i][j])\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
