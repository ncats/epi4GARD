{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65fa7f5",
   "metadata": {},
   "source": [
    "# Compiling all of the datasets into one training dataset\n",
    "\n",
    "As of this point custom labeled train, val, & test sets were created using ruled-based and statistical tagging w/IOB method\n",
    " - Disease B-DIS\n",
    " - Location B-LOC\n",
    " - Incidence/Prevalence B-EPI (tagged in case of relation extraction later on)\n",
    " - Statistics B-STAT\n",
    " \n",
    "### Additionally\n",
    "- The val set will remain unchanged\n",
    "- The test set will be modified by manual curation  \n",
    "\n",
    "There exists the MISC datasets {CoNLL(PP) location dataset, NCBI-disease, BC5CDR-disease, (i2b2-disease?)}  \n",
    "All of these have train/val/test (and train_dev for BC5CDR) sets  \n",
    "Given that my goal is to validate and test identification of Disease | Location | Incidence/Prevalence | Statistics on a realistic dataset, I will be combining the val/test/train_dev sets into the training data for the MISC datasets and only be doing val and test with my custom dataset, thus\n",
    "\n",
    "### Goals:\n",
    "1. Read in CoNLL(PP) for location\n",
    "2. Read in NCBI-disease\n",
    "3. Read in BC5CDR-disease\n",
    "3. Read in the custom dataset\n",
    "4. Combine them into a training set\n",
    "5. Save in a way that the tokenizer can read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860b5fc",
   "metadata": {},
   "source": [
    "## (1) CoNLL(PP)-Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35de691f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conllpp (/work/wzkariampuzha/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "#!pip install datasets\n",
    "from datasets import load_dataset\n",
    "coNLL = load_dataset(\"conllpp\")\n",
    "coNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a3f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER_tag '5' is B-LOC, '6' is I-LOC\n",
    "#Get numbers on the amount of location \n",
    "\n",
    "def read_loc_dataset(dataset):\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for sentence in dataset:\n",
    "        #Only add sentences that actually have location tags (i.e. meaningfully annotated sentences)\n",
    "        if (5 in sentence['ner_tags'] or 6 in sentence['ner_tags']):\n",
    "            tags = []\n",
    "            #Only keep location tags\n",
    "            for tag in sentence['ner_tags']:\n",
    "                label = 'O'\n",
    "                if tag ==5:\n",
    "                    label = 'B-LOC'\n",
    "                if tag == 6:\n",
    "                    label = 'I-LOC'\n",
    "                tags.append(label)\n",
    "            \n",
    "            #Raise error if mismatch\n",
    "            if len(sentence['tokens']) != len(tags):\n",
    "                print('mismatch')\n",
    "                print(sentence['tokens'])\n",
    "                print(tags)\n",
    "            \n",
    "            token_docs.append(sentence['tokens'])\n",
    "            tag_docs.append(tags)\n",
    "        \n",
    "    return token_docs, tag_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1f987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_loc, train_tags_loc = read_loc_dataset(coNLL[\"train\"])\n",
    "val_texts_loc, val_tags_loc = read_loc_dataset(coNLL[\"validation\"])\n",
    "test_texts_loc, test_tags_loc = read_loc_dataset(coNLL[\"test\"])\n",
    "#Combine \n",
    "#loc_tokens = [train_texts_loc, val_texts_loc, test_texts_loc]\n",
    "#loc_tags = [train_tags_loc,test_tags_loc,test_tags_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662c909a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUSSELS B-LOC\n",
      "1996-08-22 O\n",
      "\n",
      "Germany B-LOC\n",
      "'s O\n",
      "representative O\n",
      "to O\n",
      "the O\n",
      "European O\n",
      "Union O\n",
      "'s O\n",
      "veterinary O\n",
      "committee O\n",
      "Werner O\n",
      "Zwingmann O\n",
      "said O\n",
      "on O\n",
      "Wednesday O\n",
      "consumers O\n",
      "should O\n",
      "buy O\n",
      "sheepmeat O\n",
      "from O\n",
      "countries O\n",
      "other O\n",
      "than O\n",
      "Britain B-LOC\n",
      "until O\n",
      "the O\n",
      "scientific O\n",
      "advice O\n",
      "was O\n",
      "clearer O\n",
      ". O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(len((train_texts_loc[i]))): #for token in sentence\n",
    "        print(train_texts_loc[i][j], train_tags_loc[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bccc2f",
   "metadata": {},
   "source": [
    "## (2) NCBI-disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_dz = load_dataset(\"ncbi_disease\")\n",
    "ncbi_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e28171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER_tag '1' is B-DIS, '2' is I-DIS\n",
    "#https://github.com/huggingface/datasets/tree/master/datasets/ncbi_disease\n",
    "\n",
    "def read_dis_dataset(dataset):\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for sentence in dataset:\n",
    "        tags = []\n",
    "        for tag in sentence['ner_tags']:\n",
    "            label = 'O'\n",
    "            if tag ==1:\n",
    "                label = 'B-DIS'\n",
    "            if tag == 2:\n",
    "                label = 'I-DIS'\n",
    "            tags.append(label)\n",
    "            \n",
    "        #Raise error if mismatch\n",
    "        if len(sentence['tokens']) != len(tags):\n",
    "            print('mismatch')\n",
    "            print(len(sentence['tokens']))\n",
    "            print(len(tags))\n",
    "        else:\n",
    "            token_docs.append(sentence['tokens'])\n",
    "            tag_docs.append(tags)\n",
    "        \n",
    "    return token_docs, tag_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_dis, train_tags_dis = read_dis_dataset(ncbi_dz[\"train\"])\n",
    "val_texts_dis, val_tags_dis = read_dis_dataset(ncbi_dz[\"validation\"])\n",
    "test_texts_dis, test_tags_dis = read_dis_dataset(ncbi_dz[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(len((train_texts_loc[i]))): #for token in sentence\n",
    "        print(train_texts_dis[i][j], train_tags_dis[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08b9a1",
   "metadata": {},
   "source": [
    "## (3) BC5CDR-disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23db5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See what the .tsv file looks like, can remove later\n",
    "files = {'train':\"./datasets/NER/BC5CDR-disease/train.tsv\", \n",
    "         'test':\"./datasets/NER/BC5CDR-disease/test.tsv\",\n",
    "         'train_dev':\"./datasets/NER/BC5CDR-disease/train_dev.tsv\",\n",
    "         'devel':\"./datasets/NER/BC5CDR-disease/devel.tsv\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f2ea2",
   "metadata": {},
   "source": [
    "Since these datasets are not split into different abstracts, only sentences, i am going to make a list out of the four sets so that the hierarchy is the same as the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bae3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "BC5CDR_tokens,BC5CDR_tags = [],[]\n",
    "for key,value in files.items():\n",
    "    with open(value,'r') as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "        sentence_tokens, sentences_tags=[],[]\n",
    "        for row in reader:\n",
    "            if len(row)%2==0:\n",
    "                if len(row)==0:\n",
    "                    BC5CDR_tokens.append(sentence_tokens.copy())\n",
    "                    BC5CDR_tags.append(sentences_tags.copy())\n",
    "                    sentence_tokens.clear()\n",
    "                    sentences_tags.clear()\n",
    "                else:\n",
    "                    sentence_tokens.append(row[0])\n",
    "                    if row[1]=='I':\n",
    "                        sentences_tags.append('I-DIS')\n",
    "                    elif row[1]=='B':\n",
    "                        sentences_tags.append('B-DIS')\n",
    "                    else:\n",
    "                        sentences_tags.append('O')\n",
    "            else: \n",
    "                print('bad row',row)\n",
    "    file.close()\n",
    "    print('Done with',key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4e8ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(int(len(BC5CDR_tokens[i])/2)): #for token in sentence\n",
    "        print(BC5CDR_tokens[i][j], BC5CDR_tags[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b9a06",
   "metadata": {},
   "source": [
    "## (4) Read custom training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb5acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "epi_train_abstracts, epi_train_labels= [],[]\n",
    "with open('epi_train_setV2.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentence_tokens,sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                epi_train_abstracts.append(sentence_tokens.copy())\n",
    "                epi_train_labels.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff45c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background O\n",
      "Chemotherapy O\n",
      "- O\n",
      "induced O\n",
      "cardiomyopathy O\n",
      "( O\n",
      "CICM O\n",
      ") O\n",
      "and O\n",
      "heart O\n",
      "failure O\n",
      "are O\n",
      "major O\n",
      "\n",
      "There O\n",
      "is O\n",
      "limited O\n",
      "data O\n",
      "on O\n",
      "the O\n",
      "incidence B-EPI\n",
      "and O\n",
      "risk O\n",
      "factors O\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(int(len(epi_train_abstracts[i])/2)): #for token in sentence\n",
    "        print(epi_train_abstracts[i][j], epi_train_labels[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e9b21",
   "metadata": {},
   "source": [
    "## (5) Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V1\n",
    "train_texts = train_texts_loc + train_texts_dis + val_texts_loc + val_texts_dis + test_texts_loc + test_texts_dis +BC5CDR_tokens + epi_train_abstracts \n",
    "train_tags = train_tags_loc + train_tags_dis + val_tags_loc + val_tags_dis + test_tags_loc + test_tags_dis + BC5CDR_tags + epi_train_labels\n",
    "\n",
    "#train_texts = [train_texts_loc, train_texts_dis, val_texts_loc, val_texts_dis, test_texts_loc, test_texts_dis, BC5CDR_tokens, epi_train_abstracts]\n",
    "#train_tags = [train_tags_loc, train_tags_dis, val_tags_loc, val_tags_dis, test_tags_loc, test_tags_dis, BC5CDR_tags, epi_train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "868c0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V2\n",
    "train_texts = epi_train_abstracts + train_texts_loc + val_texts_loc + test_texts_loc\n",
    "train_tags = epi_train_labels + train_tags_loc + val_tags_loc + test_tags_loc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd5cb1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12289 12289\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts),len(train_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f686b4d",
   "metadata": {},
   "source": [
    "## (6) Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7d81b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background\tO\n",
      "\n",
      "Chemotherapy\tO\n",
      "\n",
      "-\tO\n",
      "\n",
      "induced\tO\n",
      "\n",
      "cardiomyopathy\tO\n",
      "\n",
      "(\tO\n",
      "\n",
      "CICM\tO\n",
      "\n",
      ")\tO\n",
      "\n",
      "and\tO\n",
      "\n",
      "heart\tO\n",
      "\n",
      "failure\tO\n",
      "\n",
      "are\tO\n",
      "\n",
      "major\tO\n",
      "\n",
      "complications\tO\n",
      "\n",
      "of\tO\n",
      "\n",
      "cancer\tO\n",
      "\n",
      "therapeutics\tO\n",
      "\n",
      "and\tO\n",
      "\n",
      "can\tO\n",
      "\n",
      "result\tO\n",
      "\n",
      "in\tO\n",
      "\n",
      "significant\tO\n",
      "\n",
      "morbidity\tO\n",
      "\n",
      "and\tO\n",
      "\n",
      "mortality\tO\n",
      "\n",
      ".\tO\n",
      "\n",
      "0\n",
      "There\tO\n",
      "\n",
      "is\tO\n",
      "\n",
      "limited\tO\n",
      "\n",
      "data\tO\n",
      "\n",
      "on\tO\n",
      "\n",
      "the\tO\n",
      "\n",
      "incidence\tB-EPI\n",
      "\n",
      "and\tO\n",
      "\n",
      "risk\tO\n",
      "\n",
      "factors\tO\n",
      "\n",
      "of\tO\n",
      "\n",
      "CICM\tO\n",
      "\n",
      "in\tO\n",
      "\n",
      "African\tO\n",
      "\n",
      "American\tO\n",
      "\n",
      "and\tO\n",
      "\n",
      "Afro\tO\n",
      "\n",
      "-\tO\n",
      "\n",
      "Caribbean\tO\n",
      "\n",
      "patients\tO\n",
      "\n",
      ".\tO\n",
      "\n",
      "Methods\tO\n",
      "\n",
      "We\tO\n",
      "\n",
      "performed\tO\n",
      "\n",
      "a\tO\n",
      "\n",
      "retrospective\tO\n",
      "\n",
      "chart\tO\n",
      "\n",
      "review\tO\n",
      "\n",
      "to\tO\n",
      "\n",
      "evaluate\tO\n",
      "\n",
      "the\tO\n",
      "\n",
      "baseline\tO\n",
      "\n",
      "characteristics\tO\n",
      "\n",
      "that\tO\n",
      "\n",
      "may\tO\n",
      "\n",
      "predispose\tO\n",
      "\n",
      "to\tO\n",
      "\n",
      "CICM\tO\n",
      "\n",
      ".\tO\n",
      "\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "with open('training_setV2.tsv', \"w\") as f:\n",
    "    for i in range(len(train_texts)): #For sentence in abstract\n",
    "        for j in range(len(train_texts[i])): #for token in sentence\n",
    "            output = str(train_texts[i][j]) +'\\t' +str(train_tags[i][j])+'\\n'\n",
    "            f.write(output)\n",
    "            if i<3:\n",
    "                print(output)\n",
    "        f.write('\\n')\n",
    "        if i%500==0:\n",
    "            print(i)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc915f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF use the dataset list instead of concatentation\n",
    "'''\n",
    "with open('training_set.tsv', \"w\") as f:\n",
    "    for s in range(len(train_texts)): #for set in training sets\n",
    "        for i in range(len(train_texts[s])): #For sentence in set\n",
    "            for j in range(len(train_texts[s][i])): #for token in sentence\n",
    "                output = str(train_texts[s][i][j]) +'\\t' +str(train_tags[s][i][j])+'\\n'\n",
    "                f.write(output)\n",
    "            f.write('\\n')\n",
    "            if i%500==0:\n",
    "                print(i)\n",
    "f.close()\n",
    "'''\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013955d1",
   "metadata": {},
   "source": [
    "## Testing adding in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training data\n",
    "import csv\n",
    "train_texts, train_tags= [],[]\n",
    "with open('training_set.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    sentence_tokens, sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                train_texts.append(sentence_tokens.copy())\n",
    "                train_tags.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374881e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(int(len(train_texts[i])/2)): #for token in sentence\n",
    "        print(train_texts[i][j], train_tags[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the validation data\n",
    "import csv\n",
    "val_texts, val_tags= [],[]\n",
    "with open('epi_val_set.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    sentence_tokens, sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                val_texts.append(sentence_tokens.copy())\n",
    "                val_tags.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(int(len(val_texts[i])/2)): #for token in sentence\n",
    "        print(val_texts[i][j], val_tags[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f01ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the testing data\n",
    "import csv\n",
    "test_texts, test_tags= [],[]\n",
    "with open('epi_test_set.tsv','r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    sentence_tokens, sentences_tags=[],[]\n",
    "    for row in reader:\n",
    "        if len(row)%2==0:\n",
    "            if len(row)==0:\n",
    "                test_texts.append(sentence_tokens.copy())\n",
    "                test_tags.append(sentences_tags.copy())\n",
    "                sentence_tokens.clear()\n",
    "                sentences_tags.clear()\n",
    "            else:\n",
    "                sentence_tokens.append(row[0])\n",
    "                sentences_tags.append(row[1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the data\n",
    "for i in range(2): #for sentence in abstract\n",
    "    for j in range(int(len(test_texts[i])/2)): #for token in sentence\n",
    "        print(test_texts[i][j], test_tags[i][j])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set(tag for doc in (train_tags+val_tags+test_tags) for tag in doc)\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "print(unique_tags)\n",
    "print(tag2id)\n",
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9736ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('dmis-lab/biobert-large-cased-v1.1')\n",
    "\n",
    "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "test_encodings = tokenizer(test_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1847291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_tags(tags, encodings, which_set):\n",
    "    labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    i=0\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        '''\n",
    "        print('doc_labels')\n",
    "        print(doc_labels)\n",
    "        print('')\n",
    "        \n",
    "        print('doc_offset')\n",
    "        print(doc_offset)\n",
    "        print('')\n",
    "        '''\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "        '''\n",
    "        print('doc_enc_labels')\n",
    "        print(doc_enc_labels)\n",
    "        print('')\n",
    "        \n",
    "        print('arr_offset')\n",
    "        print(arr_offset)\n",
    "        print('')\n",
    "        '''\n",
    "        if (np.count_nonzero((arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)) != len(doc_labels)):\n",
    "            print(np.count_nonzero((arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)))\n",
    "            print(len(doc_labels))\n",
    "            if which_set =='train':\n",
    "                train_texts.pop(i)\n",
    "                train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "            if which_set =='val':\n",
    "                val_texts.pop(i)\n",
    "                val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "            if which_set =='test':\n",
    "                test_texts.pop(i)\n",
    "                test_encodings = tokenizer(test_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "            print('-----------------------------------')\n",
    "        else:\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "            doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "            encoded_labels.append(doc_enc_labels.tolist())\n",
    "        i+=1\n",
    "        \n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e4add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = encode_tags(train_tags, train_encodings,'train')\n",
    "print(len(train_labels), len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391144d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_labels = encode_tags(val_tags, val_encodings,'val')\n",
    "print(len(val_labels), len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = encode_tags(test_tags, test_encodings,'test')\n",
    "print(len(test_labels), len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f75276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Format_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
    "val_encodings.pop(\"offset_mapping\")\n",
    "test_encodings.pop(\"offset_mapping\")\n",
    "\n",
    "train_dataset = Format_Dataset(train_encodings, train_labels)\n",
    "val_dataset = Format_Dataset(val_encodings, val_labels)\n",
    "test_dataset = Format_Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "model = BertForTokenClassification.from_pretrained('dmis-lab/biobert-large-cased-v1.1', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6511e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified\n",
    "from transformers import EvalPrediction\n",
    "from torch import nn\n",
    "def align_predictions(predictions: np.ndarray, label_ids: np.ndarray): # -> Tuple[List[int], List[int]]\n",
    "        preds = np.argmax(predictions, axis=2)\n",
    "        #print('preds.shape',preds.shape)\n",
    "        batch_size, seq_len = preds.shape\n",
    "        \n",
    "        out_label_list = [[] for _ in range(batch_size)]\n",
    "        preds_list = [[] for _ in range(batch_size)]\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(seq_len):\n",
    "                if label_ids[i, j] != nn.CrossEntropyLoss().ignore_index:\n",
    "                    out_label_list[i].append(id2tag[label_ids[i][j]])\n",
    "                    preds_list[i].append(id2tag[preds[i][j]])\n",
    "\n",
    "        return preds_list, out_label_list\n",
    "\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "def compute_metrics(p: EvalPrediction): #-> Dict\n",
    "    preds_list, out_label_list = align_predictions(p.predictions, p.label_ids)\n",
    "    return {\n",
    "        \"precision\": precision_score(out_label_list, preds_list),\n",
    "        \"recall\": recall_score(out_label_list, preds_list),\n",
    "        \"f1\": f1_score(out_label_list, preds_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'./results',          # output directory\n",
    "    overwrite_output_dir = True,\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=64,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f'./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    seed = 1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics      # compute metric defined above\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dafaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "#Seed is a helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3da75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebff092",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "# For convenience, we also re-save the tokenizer to the same directory,\n",
    "# so that you can share your model easily on huggingface.co/models =)\n",
    "if trainer.is_world_process_zero():\n",
    "    tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained('./results/', num_labels=len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd85955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import os\n",
    "results = {}\n",
    "result = trainer.evaluate()\n",
    "output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        for key, value in result.items():\n",
    "            writer.write(\"%s = %s\\n\" % (key, value))\n",
    "            results.update(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad8407",
   "metadata": {},
   "source": [
    "Testing & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4614b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Align Predictions\n",
    "preds_list, _ = align_predictions(predictions, label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction results\n",
    "\n",
    "output_test_results_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_test_results_file, \"w\") as writer:\n",
    "        for key, value in metrics.items():\n",
    "            writer.write(\"%s = %s\\n\" % (key, value))\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f093ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save actual predictions\n",
    "\n",
    "output_test_predictions_file = os.path.join(training_args.output_dir, \"test_predictions.txt\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_test_predictions_file, \"w\") as writer:\n",
    "        i = 0\n",
    "        for sentence in test_texts:\n",
    "            j=0\n",
    "            for token in sentence:\n",
    "                output = token +'\\t' +preds_list[i][j]+'\\n'\n",
    "                writer.write(output)\n",
    "                j+=1\n",
    "            i+=1\n",
    "''''''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
